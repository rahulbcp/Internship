{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f09801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import InvalidArgumentException\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f96b42",
   "metadata": {},
   "source": [
    "## Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20362588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                                  \"Bath Song\"   \n",
       "4    5.                               \"Shape of You\"   \n",
       "5    6.                              \"See You Again\"   \n",
       "6    7.                          \"Wheels on the Bus\"   \n",
       "7    8.                \"Phonics Song with Two Words\"   \n",
       "8    9.                                \"Uptown Funk\"   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                     \"Axel F\"   \n",
       "14  15.                                      \"Sugar\"   \n",
       "15  16.                             \"Counting Stars\"   \n",
       "16  17.                                       \"Roar\"   \n",
       "17  18.                        \"Baa Baa Black Sheep\"   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"   \n",
       "19  20.                                      \"Sorry\"   \n",
       "20  21.                             \"Lakdi Ki Kathi\"   \n",
       "21  22.                          \"Thinking Out Loud\"   \n",
       "22  23.                                 \"Dark Horse\"   \n",
       "23  24.          \"Humpty the train on a fruits ride\"   \n",
       "24  25.                                    \"Perfect\"   \n",
       "25  26.                                 \"Let Her Go\"   \n",
       "26  27.                                      \"Faded\"   \n",
       "27  28.                             \"Girls Like You\"   \n",
       "28  29.                      \"Shree Hanuman Chalisa\"   \n",
       "29  30.                                    \"Lean On\"   \n",
       "\n",
       "                                               Artist        Upload date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   13.48  \n",
       "1    8.28  \n",
       "2    6.82  \n",
       "3    6.45  \n",
       "4    6.11  \n",
       "5    6.05  \n",
       "6    5.62  \n",
       "7    5.52  \n",
       "8    5.05  \n",
       "9    4.99  \n",
       "10   4.92  \n",
       "11   4.56  \n",
       "12   4.46  \n",
       "13   4.09  \n",
       "14   3.95  \n",
       "15   3.89  \n",
       "16   3.89  \n",
       "17   3.80  \n",
       "18   3.75  \n",
       "19   3.72  \n",
       "20   3.71  \n",
       "21   3.67  \n",
       "22   3.60  \n",
       "23   3.58  \n",
       "24   3.56  \n",
       "25   3.53  \n",
       "26   3.53  \n",
       "27   3.50  \n",
       "28   3.48  \n",
       "29   3.48  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Chrome()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "# Scrape the following details\n",
    "rank = []\n",
    "name = []\n",
    "artist = []\n",
    "upload_date = []\n",
    "views = []\n",
    "\n",
    "ranking = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in ranking:    \n",
    "    rank.append(i.text)\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for j in names:\n",
    "    name.append(j.text.split(\"[\")[0].strip())\n",
    "art = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for k in art:\n",
    "    artist.append(k.text)\n",
    "upload = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "for l in upload:\n",
    "    upload_date.append(l.text)\n",
    "view = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]') \n",
    "for m in view:\n",
    "    views.append(m.text)\n",
    "\n",
    "#Saving in data frame\n",
    "df = pd.DataFrame({\"Rank\":rank[0:30],\"Name\":name[0:30],\"Artist\":artist[0:30],\"Upload date\":upload_date[0:30],\"Views\":views[0:30]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460efa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbeaaed",
   "metadata": {},
   "source": [
    "## Question 2 Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c82ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Chrome()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://www.bcci.tv/.\")\n",
    "#Close the pop-up window\n",
    "close = driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]')\n",
    "close.click()\n",
    "#Maximize the window\n",
    "driver.maximize_window()\n",
    "#reach to international fixture page\n",
    "fixture = driver.find_element(By.XPATH,'//div[@id=\"imw-international-men\"]/a[2]')\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398ca4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>14 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>11 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>8 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>22 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>8 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>31 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>28 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Series  \\\n",
       "0    ICC MENS WORLD CUP 2023   \n",
       "1    ICC MENS WORLD CUP 2023   \n",
       "2    ICC MENS WORLD CUP 2023   \n",
       "3    ICC MENS WORLD CUP 2023   \n",
       "4    ICC MENS WORLD CUP 2023   \n",
       "..                       ...   \n",
       "105            ASIA CUP 2022   \n",
       "106            ASIA CUP 2022   \n",
       "107            ASIA CUP 2022   \n",
       "108            ASIA CUP 2022   \n",
       "109            ASIA CUP 2022   \n",
       "\n",
       "                                                 Place               Date  \\\n",
       "0        Maharashtra Cricket Association Stadium, Pune   19 OCTOBER, 2023   \n",
       "1                     Narendra Modi Stadium, Ahmedabad   14 OCTOBER, 2023   \n",
       "2                          Arun Jaitley Stadium, Delhi   11 OCTOBER, 2023   \n",
       "3                      MA Chidambaram Stadium, Chennai    8 OCTOBER, 2023   \n",
       "4    Himachal Pradesh Cricket Association Stadium, ...   22 OCTOBER, 2023   \n",
       "..                                                 ...                ...   \n",
       "105         Dubai International Cricket Stadium, Dubai  8 SEPTEMBER, 2022   \n",
       "106         Dubai International Cricket Stadium, Dubai  6 SEPTEMBER, 2022   \n",
       "107         Dubai International Cricket Stadium, Dubai  4 SEPTEMBER, 2022   \n",
       "108         Dubai International Cricket Stadium, Dubai    31 AUGUST, 2022   \n",
       "109         Dubai International Cricket Stadium, Dubai    28 AUGUST, 2022   \n",
       "\n",
       "            Time  \n",
       "0    2:00 PM IST  \n",
       "1    2:00 PM IST  \n",
       "2    2:00 PM IST  \n",
       "3    2:00 PM IST  \n",
       "4    2:00 PM IST  \n",
       "..           ...  \n",
       "105  7:30 PM IST  \n",
       "106  7:30 PM IST  \n",
       "107  7:30 PM IST  \n",
       "108  7:30 PM IST  \n",
       "109  7:30 PM IST  \n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#click on \"All teams\" dropdown\n",
    "drop = driver.find_element(By.XPATH,'(//div[@ng-click=\"cSBShowList($event)\"])[1]')\n",
    "drop.click()\n",
    "#find India\n",
    "find = driver.find_element(By.XPATH,'//input[@ng-model=\"cSBTeamsListSearch\"]')\n",
    "find.send_keys(\"India\")\n",
    "result = driver.find_element(By.XPATH,'(//div[@ng-click=\"resultsfilterByTeam(list,\\'Upcoming\\')\"])[1]')\n",
    "result.click()\n",
    "#scrape following details\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time = []\n",
    "serie = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in serie:\n",
    "    series.append(i.text)\n",
    "places = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "for j in places:\n",
    "    place.append(j.text)\n",
    "dates = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')    \n",
    "for k in dates:\n",
    "    date.append(k.text)\n",
    "times = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for l in times:\n",
    "    time.append(l.text)\n",
    "#saving in dataframe\n",
    "df = pd.DataFrame({\"Series\":series,\"Place\":place,\"Date\":date,\"Time\":time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3598f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d223f0",
   "metadata": {},
   "source": [
    "## Question 3 Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf14378a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                      2,632,792   \n",
       "1     2                 Tamil Nadu                      1,630,208   \n",
       "2     3              Uttar Pradesh                      1,584,764   \n",
       "3     4                    Gujarat                      1,502,899   \n",
       "4     5                  Karnataka                      1,493,127   \n",
       "5     6                West Bengal                      1,089,898   \n",
       "6     7                  Rajasthan                        942,586   \n",
       "7     8             Andhra Pradesh                        862,957   \n",
       "8     9                  Telangana                        861,031   \n",
       "9    10             Madhya Pradesh                        809,592   \n",
       "10   11                     Kerala                        781,653   \n",
       "11   12                      Delhi                        774,870   \n",
       "12   13                    Haryana                        734,163   \n",
       "13   14                      Bihar                        530,363   \n",
       "14   15                     Punjab                        526,376   \n",
       "15   16                     Odisha                        487,805   \n",
       "16   17                      Assam                        315,881   \n",
       "17   18               Chhattisgarh                        304,063   \n",
       "18   19                  Jharkhand                        297,204   \n",
       "19   20                Uttarakhand                        245,895   \n",
       "20   21            Jammu & Kashmir                        155,956   \n",
       "21   22           Himachal Pradesh                        153,845   \n",
       "22   23                        Goa                         73,170   \n",
       "23   24                    Tripura                         49,845   \n",
       "24   25                 Chandigarh                         42,114   \n",
       "25   26                 Puducherry                         34,433   \n",
       "26   27                  Meghalaya                         33,481   \n",
       "27   28                     Sikkim                         28,723   \n",
       "28   29                    Manipur                         27,870   \n",
       "29   30                   Nagaland                         27,283   \n",
       "30   31          Arunachal Pradesh                         24,603   \n",
       "31   32                    Mizoram                         22,287   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                               -       13.94%        399.921  \n",
       "1                       1,845,853        8.63%        247.629  \n",
       "2                       1,687,818        8.39%        240.726  \n",
       "3                               -        7.96%        228.290  \n",
       "4                       1,631,977        7.91%        226.806  \n",
       "5                       1,253,832        5.77%        165.556  \n",
       "6                       1,020,989        4.99%        143.179  \n",
       "7                         972,782        4.57%        131.083  \n",
       "8                         969,604        4.56%        130.791  \n",
       "9                         906,672        4.29%        122.977  \n",
       "10                              -        4.14%        118.733  \n",
       "11                        856,112        4.10%        117.703  \n",
       "12                        831,610        3.89%        111.519  \n",
       "13                        611,804        2.81%         80.562  \n",
       "14                        574,760        2.79%         79.957  \n",
       "15                        521,275        2.58%         74.098  \n",
       "16                              -        1.67%         47.982  \n",
       "17                        329,180        1.61%         46.187  \n",
       "18                        328,598        1.57%         45.145  \n",
       "19                              -        1.30%         37.351  \n",
       "20                              -        0.83%         23.690  \n",
       "21                        165,472        0.81%         23.369  \n",
       "22                         80,449        0.39%         11.115  \n",
       "23                         55,984        0.26%          7.571  \n",
       "24                              -        0.22%          6.397  \n",
       "25                         38,253        0.18%          5.230  \n",
       "26                         36,572        0.18%          5.086  \n",
       "27                         32,496        0.15%          4.363  \n",
       "28                         31,790        0.15%          4.233  \n",
       "29                              -        0.14%          4.144  \n",
       "30                              -        0.13%          3.737  \n",
       "31                         26,503        0.12%          3.385  \n",
       "32                              -            -              -  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Firefox()\n",
    "# Open the requested URL\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "# go to economy page\n",
    "page = driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button')\n",
    "page.click()\n",
    "# go to India\n",
    "go = driver.find_element(By.XPATH,'//a[@href=\"economy/india-statistics.php\"]')\n",
    "go.click()\n",
    "#find GDP of Indian states\n",
    "find = driver.find_element(By.XPATH,'//a[@href=\"india/indian-states-gdp.php\"]')\n",
    "find.click()\n",
    "#Scraping following details\n",
    "rank = []\n",
    "state = []\n",
    "gsdp_18 = []\n",
    "gsdp_19 = []\n",
    "share = []\n",
    "gdp = []\n",
    "\n",
    "ranks = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[1]')\n",
    "for i in ranks:\n",
    "    rank.append(i.text)\n",
    "states = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[2]')\n",
    "for j in states:\n",
    "    state.append(j.text)\n",
    "gsdp_18_19 = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[4]')\n",
    "for k in gsdp_18_19:\n",
    "    gsdp_18.append(k.text)\n",
    "gsdp_19_20 = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[3]')\n",
    "for l in gsdp_19_20:\n",
    "    gsdp_19.append(l.text)\n",
    "shares = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[5]')\n",
    "for m in shares:\n",
    "    share.append(m.text)\n",
    "gdps = driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[6]')\n",
    "for n in gdps:\n",
    "    gdp.append(n.text)\n",
    "df = pd.DataFrame({\"Rank\":rank,\"State\":state,\"GSDP(18-19)- at current prices\":gsdp_18,\"GSDP(19-20)- at current prices\":gsdp_19,\"Share(18-19)\":share,\"GDP($ billion)\":gdp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef645ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7ba4d",
   "metadata": {},
   "source": [
    "## Question 4 - Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "064c4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Chrome()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://github.com/\")\n",
    "#go to trending option\n",
    "open_1 = driver.find_element(By.XPATH,'(//button[@type=\"button\"])[5]')\n",
    "open_1.click()\n",
    "trend = driver.find_element(By.XPATH,'//a[@href=\"/trending\"]')\n",
    "trend.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3a356f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA / TensorRT-LLM</td>\n",
       "      <td>TensorRT-LLM provides users with an easy-to-us...</td>\n",
       "      <td>68</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>localsend / localsend</td>\n",
       "      <td>An open source cross-platform alternative to A...</td>\n",
       "      <td>889</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenBMB / XAgent</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td>175</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WisdomShell / codeshell</td>\n",
       "      <td>A series of code large language models develop...</td>\n",
       "      <td>37</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WisdomShell / codeshell-vscode</td>\n",
       "      <td>An intelligent coding assistant plugin for Vis...</td>\n",
       "      <td>23</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neuralmagic / deepsparse</td>\n",
       "      <td>Sparsity-aware deep learning inference runtime...</td>\n",
       "      <td>109</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Planetary-Computers / autotab-starter</td>\n",
       "      <td>Build browser agents for real world tasks</td>\n",
       "      <td>19</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ByteByteGoHq / system-design-101</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td>1,700</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>887</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>danieldonda / Cybersecurity101</td>\n",
       "      <td>Um guia abrangente para iniciantes na área de ...</td>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>imartinez / privateGPT</td>\n",
       "      <td>Interact with your documents using the power o...</td>\n",
       "      <td>5,134</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>radius-project / radius</td>\n",
       "      <td>Radius is a cloud-native, portable application...</td>\n",
       "      <td>17</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ionic-team / ionic-framework</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td>13,690</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>slowmist / SlowMist-Learning-Roadmap-for-Becom...</td>\n",
       "      <td>Smart contract audit skills roadmap for beginn...</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e2b-dev / awesome-ai-agents</td>\n",
       "      <td>A list of AI autonomous agents</td>\n",
       "      <td>156</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>felipemotarocha / fullstackweek-store</td>\n",
       "      <td>-</td>\n",
       "      <td>30</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AntonOsika / gpt-engineer</td>\n",
       "      <td>Specify what you want it to build, the AI asks...</td>\n",
       "      <td>7,363</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>commaai / openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>7,781</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apexcharts / apexcharts.js</td>\n",
       "      <td>📊 Interactive JavaScript Charts built on SVG</td>\n",
       "      <td>1,206</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TheRealJoelmatic / RemoveAdblockThing</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td>68</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>thuml / Time-Series-Library</td>\n",
       "      <td>A Library for Advanced Deep Time Series Models.</td>\n",
       "      <td>360</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>danielgross / localpilot</td>\n",
       "      <td>-</td>\n",
       "      <td>84</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>babysor / MockingBird</td>\n",
       "      <td>🚀AI拟声: 5秒内克隆您的声音并生成任意语音内容 Clone a voice in 5 s...</td>\n",
       "      <td>4,792</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cloudflare / workers-sdk</td>\n",
       "      <td>⛅️ Home to Wrangler, the CLI for Cloudflare Wo...</td>\n",
       "      <td>384</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hashicorp / terraform-provider-aws</td>\n",
       "      <td>Terraform AWS provider</td>\n",
       "      <td>8,392</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0                               NVIDIA / TensorRT-LLM   \n",
       "1                               localsend / localsend   \n",
       "2                                    OpenBMB / XAgent   \n",
       "3                             WisdomShell / codeshell   \n",
       "4                      WisdomShell / codeshell-vscode   \n",
       "5                            neuralmagic / deepsparse   \n",
       "6               Planetary-Computers / autotab-starter   \n",
       "7                    ByteByteGoHq / system-design-101   \n",
       "8                cloudcommunity / Free-Certifications   \n",
       "9                      danieldonda / Cybersecurity101   \n",
       "10                             imartinez / privateGPT   \n",
       "11                            radius-project / radius   \n",
       "12                       ionic-team / ionic-framework   \n",
       "13  slowmist / SlowMist-Learning-Roadmap-for-Becom...   \n",
       "14                        e2b-dev / awesome-ai-agents   \n",
       "15              felipemotarocha / fullstackweek-store   \n",
       "16                          AntonOsika / gpt-engineer   \n",
       "17                                commaai / openpilot   \n",
       "18                         apexcharts / apexcharts.js   \n",
       "19              TheRealJoelmatic / RemoveAdblockThing   \n",
       "20                        thuml / Time-Series-Library   \n",
       "21                           danielgross / localpilot   \n",
       "22                              babysor / MockingBird   \n",
       "23                           cloudflare / workers-sdk   \n",
       "24                 hashicorp / terraform-provider-aws   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   TensorRT-LLM provides users with an easy-to-us...                 68   \n",
       "1   An open source cross-platform alternative to A...                889   \n",
       "2    An Autonomous LLM Agent for Complex Task Solving                175   \n",
       "3   A series of code large language models develop...                 37   \n",
       "4   An intelligent coding assistant plugin for Vis...                 23   \n",
       "5   Sparsity-aware deep learning inference runtime...                109   \n",
       "6           Build browser agents for real world tasks                 19   \n",
       "7   Explain complex systems using visuals and simp...              1,700   \n",
       "8    A curated list of free courses & certifications.                887   \n",
       "9   Um guia abrangente para iniciantes na área de ...                 11   \n",
       "10  Interact with your documents using the power o...              5,134   \n",
       "11  Radius is a cloud-native, portable application...                 17   \n",
       "12  A powerful cross-platform UI toolkit for build...             13,690   \n",
       "13  Smart contract audit skills roadmap for beginn...                 26   \n",
       "14                     A list of AI autonomous agents                156   \n",
       "15                                                  -                 30   \n",
       "16  Specify what you want it to build, the AI asks...              7,363   \n",
       "17  openpilot is an open source driver assistance ...              7,781   \n",
       "18       📊 Interactive JavaScript Charts built on SVG              1,206   \n",
       "19  Removes The \"Ad blocker are not allowed on You...                 68   \n",
       "20    A Library for Advanced Deep Time Series Models.                360   \n",
       "21                                                  -                 84   \n",
       "22  🚀AI拟声: 5秒内克隆您的声音并生成任意语音内容 Clone a voice in 5 s...              4,792   \n",
       "23  ⛅️ Home to Wrangler, the CLI for Cloudflare Wo...                384   \n",
       "24                             Terraform AWS provider              8,392   \n",
       "\n",
       "   Language used  \n",
       "0            C++  \n",
       "1           Dart  \n",
       "2     TypeScript  \n",
       "3         Python  \n",
       "4     TypeScript  \n",
       "5         Python  \n",
       "6         Python  \n",
       "7              -  \n",
       "8              -  \n",
       "9              -  \n",
       "10        Python  \n",
       "11            Go  \n",
       "12    TypeScript  \n",
       "13             -  \n",
       "14             -  \n",
       "15    TypeScript  \n",
       "16        Python  \n",
       "17        Python  \n",
       "18    JavaScript  \n",
       "19    JavaScript  \n",
       "20         Shell  \n",
       "21        Python  \n",
       "22        Python  \n",
       "23    TypeScript  \n",
       "24            Go  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping below details\n",
    "title = []\n",
    "desc = []\n",
    "count = []\n",
    "lang = []\n",
    "titles = driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]')\n",
    "for a in titles:\n",
    "    try:\n",
    "        title.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        title.append('-')\n",
    "counts = driver.find_elements(By.XPATH, '//a[@class=\"Link Link--muted d-inline-block mr-3\"][2]')\n",
    "for b in counts:\n",
    "    try:\n",
    "        count.append(b.text)\n",
    "    except NoSuchElementException:\n",
    "        count.append('-')\n",
    "#Scraping all urls\n",
    "urls = []\n",
    "url_element = driver.find_elements(By.XPATH, '//h2/a')\n",
    "for url in url_element:\n",
    "    urls.append(url.get_attribute('href'))\n",
    "for a_1 in urls:\n",
    "    driver.get(a_1)\n",
    "    try:\n",
    "        description = driver.find_element(By.XPATH, '//p[@class=\"f4 my-3\"]')\n",
    "        desc.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        desc.append('-')\n",
    "    try:\n",
    "        language = driver.find_element(By.XPATH, '(//span[@class=\"color-fg-default text-bold mr-1\"])[1]')\n",
    "        lang.append(language.text)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "#saving data in DataFrame\n",
    "df = pd.DataFrame({'Repository title': title,'Repository description': desc,'Contributors count': count,'Language used': lang})\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63fc0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90336f8",
   "metadata": {},
   "source": [
    "## Question 5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa64aeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First Person Shooter</td>\n",
       "      <td>Drake Featuring J. Cole</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDGAF</td>\n",
       "      <td>Drake Featuring Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>God Gave Me A Girl</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Y Lloro</td>\n",
       "      <td>Junior H</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Telekinesis</td>\n",
       "      <td>Travis Scott Featuring SZA &amp; Future</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Seven</td>\n",
       "      <td>Jung Kook Featuring Latto</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Stars Like Confetti</td>\n",
       "      <td>Dustin Lynch</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song name                          Artist name Last week rank  \\\n",
       "0   First Person Shooter              Drake Featuring J. Cole              -   \n",
       "1                  IDGAF                 Drake Featuring Yeat              -   \n",
       "2         Virginia Beach                                Drake              -   \n",
       "3     Paint The Town Red                             Doja Cat              1   \n",
       "4        Calling For You            Drake Featuring 21 Savage              -   \n",
       "..                   ...                                  ...            ...   \n",
       "95    God Gave Me A Girl                    Russell Dickerson             90   \n",
       "96               Y Lloro                             Junior H              -   \n",
       "97           Telekinesis  Travis Scott Featuring SZA & Future             72   \n",
       "98                 Seven            Jung Kook Featuring Latto             57   \n",
       "99   Stars Like Confetti                         Dustin Lynch             89   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1              1  \n",
       "1          2              1  \n",
       "2          3              1  \n",
       "3          1             10  \n",
       "4          5              1  \n",
       "..       ...            ...  \n",
       "95        90              2  \n",
       "96        97              1  \n",
       "97        26             11  \n",
       "98         1             13  \n",
       "99        89              2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Firefox()\n",
    "# Open the requested URL\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "#click on top 100 songs on billiboard\n",
    "songs = driver.find_element(By.XPATH,'(//a[@href=\"https://www.billboard.com/charts/hot-100/\"])[1]')\n",
    "songs.click()\n",
    "#scraping below requested details\n",
    "song = []\n",
    "artist = []\n",
    "last = []\n",
    "peak = []\n",
    "week = []\n",
    "songs = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for a in songs:\n",
    "    song.append(a.text)\n",
    "artists = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')  \n",
    "for b in artists:\n",
    "    artist.append(b.text)\n",
    "lasts = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "for c in lasts:\n",
    "    last.append(c.text)\n",
    "peaks = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "for d in peaks:\n",
    "    peak.append(d.text)\n",
    "weeks = driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "for e in weeks:\n",
    "    week.append(e.text)\n",
    "#save in dataframe\n",
    "df = pd.DataFrame({\"Song name\":song,\"Artist name\":artist,\"Last week rank\":last,\"Peak rank\":peak,\"Weeks on board\":week})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7301ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e87cc5",
   "metadata": {},
   "source": [
    "## Question 6 Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aaebfdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Firefox()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "#scraping following details\n",
    "name = []\n",
    "author = []\n",
    "volume = []\n",
    "publish = []\n",
    "genre = []\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[2]')\n",
    "for a in names:\n",
    "    name.append(a.text)\n",
    "authors = driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[3]')  \n",
    "for b in authors:\n",
    "    author.append(b.text)\n",
    "volumes = driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[4]')    \n",
    "for c in volumes:\n",
    "    volume.append(c.text)\n",
    "publishes = driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[5]') \n",
    "for d in publishes:\n",
    "    publish.append(d.text)\n",
    "genres = driver.find_elements(By.XPATH,'//div[@class=\"embed block\"]/table/tbody/tr/td[6]')\n",
    "for e in genres:\n",
    "    genre.append(e.text)\n",
    "#saving in dataframe\n",
    "df = pd.DataFrame({\"Book name\":name,\"Author name\":author,\"Volumes sold\":volume,\"Publisher\":publish,\"Genre\":genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81f59dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0545a",
   "metadata": {},
   "source": [
    "## Question 7 Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f69787e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,213,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,283,589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,050,605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>270,502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,213,900  \n",
       "1    51 min     8.7  1,283,589  \n",
       "2    44 min     8.1  1,050,605  \n",
       "3    60 min     7.5    308,676  \n",
       "4    43 min     7.6    267,615  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,970  \n",
       "96   50 min     7.8     65,033  \n",
       "97   42 min     8.1    211,964  \n",
       "98   45 min       7     44,120  \n",
       "99  572 min     8.6    270,502  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Firefox()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "#scraping following details\n",
    "name = []\n",
    "span = []\n",
    "genre = []\n",
    "time = []\n",
    "rating = []\n",
    "vote = []\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/h3/a')\n",
    "for a in names:\n",
    "    name.append(a.text)\n",
    "spans = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/h3/span[2]')\n",
    "for b in spans:\n",
    "    span.append(b.text)\n",
    "genres = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/p/span[5]')\n",
    "for c in genres:\n",
    "    genre.append(c.text)\n",
    "times = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/p/span[3]') \n",
    "for d in times:\n",
    "    time.append(d.text)\n",
    "ratings = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/div/div[1]/span[2]')\n",
    "for e in ratings:\n",
    "    rating.append(e.text)\n",
    "votes = driver.find_elements(By.XPATH,'//div[@class=\"lister-list\"]/div/div[2]/p[4]/span[2]')\n",
    "for f in votes:\n",
    "    vote.append(f.text)\n",
    "#saving in dataframe\n",
    "df = pd.DataFrame({\"Name\":name,\"Year span\":span,\"Genre\":genre,\"Run time\":time,\"Ratings\":rating,\"Votes\":vote})\n",
    "df\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0faf2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a414b4b",
   "metadata": {},
   "source": [
    "## Question 8 - Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32f3a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the Chrome\n",
    "driver = webdriver.Chrome()\n",
    "# Open the requested URL\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()\n",
    "#go to dataset\n",
    "dataset = driver.find_element(By.XPATH,'(//a[@href=\"/datasets\"])[2]')\n",
    "dataset.click()\n",
    "#close unwanted pop-up\n",
    "close = driver.find_element(By.XPATH,'//div[@class=\"alert fixed bottom-0\"]/div[2]/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d44f70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "urls = []\n",
    "while True:\n",
    "    # Scrape dataset URLs from the current page\n",
    "    url_elements = driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for element in url_elements:\n",
    "        urls.append(element.get_attribute('href'))\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//div[@class=\"btn-group\"]/button[2]')     \n",
    "        next_button.click()\n",
    "        time.sleep(5)\n",
    "    except ElementClickInterceptedException:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2dd754f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Moral Reasoner</td>\n",
       "      <td>Domain-Theory</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>202</td>\n",
       "      <td>-</td>\n",
       "      <td>5/31/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Sattriya_Dance_Single_Hand_Gestures Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1450</td>\n",
       "      <td>-</td>\n",
       "      <td>7/21/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>EBL Domain Theories</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>TamilSentiMix</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>15744</td>\n",
       "      <td>-</td>\n",
       "      <td>8/13/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>TUNADROMD</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>4465</td>\n",
       "      <td>242</td>\n",
       "      <td>6/20/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Dataset name           Data type  \\\n",
       "0                                           Iris             Tabular   \n",
       "1                                  Heart Disease        Multivariate   \n",
       "2                                          Adult        Multivariate   \n",
       "3                                           Wine             Tabular   \n",
       "4           Breast Cancer Wisconsin (Diagnostic)        Multivariate   \n",
       "..                                           ...                 ...   \n",
       "652                               Moral Reasoner       Domain-Theory   \n",
       "653  Sattriya_Dance_Single_Hand_Gestures Dataset        Multivariate   \n",
       "654                          EBL Domain Theories                   -   \n",
       "655                                TamilSentiMix  Multivariate, Text   \n",
       "656                                    TUNADROMD             Tabular   \n",
       "\n",
       "               Task              Attribute type No of instances  \\\n",
       "0    Classification                        Real             150   \n",
       "1    Classification  Categorical, Integer, Real             303   \n",
       "2    Classification        Categorical, Integer           48842   \n",
       "3    Classification               Integer, Real             178   \n",
       "4    Classification                        Real             569   \n",
       "..              ...                         ...             ...   \n",
       "652               -                           -             202   \n",
       "653  Classification                           -            1450   \n",
       "654               -                           -               -   \n",
       "655  Classification                 Categorical           15744   \n",
       "656  Classification                     Integer            4465   \n",
       "\n",
       "    No of attribute         Year  \n",
       "0                 4    6/30/1988  \n",
       "1                13    6/30/1988  \n",
       "2                14    4/30/1996  \n",
       "3                13    6/30/1991  \n",
       "4                30   10/31/1995  \n",
       "..              ...          ...  \n",
       "652               -    5/31/1994  \n",
       "653               -    7/21/2019  \n",
       "654               -            -  \n",
       "655               -    8/13/2023  \n",
       "656             242    6/20/2023  \n",
       "\n",
       "[657 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape dataset details\n",
    "name = []\n",
    "type_1 = []\n",
    "task = []\n",
    "attribute = []\n",
    "no_1 = []\n",
    "no_attribute = []\n",
    "year = []\n",
    "final_years = []\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        names = driver.find_element(By.XPATH, '(//div[@class=\"flex items-center gap-4\"])[1]')\n",
    "        name.append(names.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('-')\n",
    "    try:\n",
    "        types = driver.find_element(By.XPATH, '//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[1]/p')\n",
    "        type_1.append(types.text)\n",
    "    except NoSuchElementException:\n",
    "        type_1.append('-')\n",
    "    try:\n",
    "        tasks = driver.find_element(By.XPATH, '//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[3]/p')\n",
    "        task.append(tasks.text)\n",
    "    except NoSuchElementException:\n",
    "        task.append('-')\n",
    "    try:\n",
    "        attributes = driver.find_element(By.XPATH, '//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[4]/p')\n",
    "        attribute.append(attributes.text)\n",
    "    except NoSuchElementException:\n",
    "        attribute.append('-')\n",
    "    try:\n",
    "        nos = driver.find_element(By.XPATH, '//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p')\n",
    "        no_1.append(nos.text)\n",
    "    except NoSuchElementException:\n",
    "        no_1.append('-')\n",
    "    try:\n",
    "        no_attributes = driver.find_element(By.XPATH, '//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[6]/p')\n",
    "        no_attribute.append(no_attributes.text)\n",
    "    except NoSuchElementException:\n",
    "        no_attribute.append('-')\n",
    "    try:\n",
    "        years = driver.find_element(By.XPATH, '//h2[@class=\"text-sm text-primary-content\"]')\n",
    "        year.append(years.text)               \n",
    "    except NoSuchElementException:\n",
    "        year.append('-')\n",
    "#Replacing \"Donated on\" to ''\n",
    "for a in year:\n",
    "    final_years.append(a.replace('Donated on',''))\n",
    "# Saving in DataFrame\n",
    "df = pd.DataFrame({\"Dataset name\": name, \"Data type\": type_1, \"Task\": task, \"Attribute type\": attribute, \"No of instances\": no_1, \"No of attribute\": no_attribute, \"Year\": final_years})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "edf6a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
